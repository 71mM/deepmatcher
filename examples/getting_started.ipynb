{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aXpIRSAQ-cw1"
   },
   "source": [
    "# Getting started with DeepMatcher\n",
    "\n",
    "Note: you can run **[this notebook live in Google Colab](https://colab.research.google.com/github/sidharthms/deepmatcher/blob/master/examples/getting_started.ipynb)** and use free GPUs provided by Google.\n",
    "\n",
    "This tutorial describes how to effortlessly perform entity matching using deep neural networks. Specifically, we will see how to match pairs of tuples (also called data records or table rows) to determine if they refer to the same real world entity. To do so, we will need labeled examples as input, i.e., tuple pairs which have been annotated as matches or non-matches. This will be used to train our neural network using supervised learning. At the end of this tutorial, you will have a trained neural network as output which you can easily apply to unlabeled tuple pairs to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an overview, here are the 4 steps to use `deepmatcher` which we will go through in this tutorial:\n",
    "\n",
    "<ol start=\"0\">\n",
    "  <li>Setup</li>\n",
    "  <li>Process data</li>\n",
    "  <li>Define neural network model</li>\n",
    "  <li>Train model</li>\n",
    "  <li>Apply model to new data</li>\n",
    "</ol>\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Setup\n",
    "\n",
    "If you are running this notebook inside Colab, you will first need to install necessary packages by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LEiDiDNz-PEG"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    !pip install -q http://download.pytorch.org/whl/cu80/torch-0.3.1-cp36-cp36m-linux_x86_64.whl\n",
    "    !pip install -q --process-dependency-links git+https://github.com/sidharthms/deepmatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import `deepmatcher` which will do all the heavy lifting to build and train neural network models for entity matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepmatcher as dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend having a GPU available for the training in Step 4. In case a GPU is not available, we will use all available CPU cores. You can run the following command to determine if a GPU is available and will be used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download sample data for entity matching\n",
    "\n",
    "Now let's get some sample data to play with in this tutorial. We will need three sets of labeled data and one set of unlabeled data:\n",
    "\n",
    "1. **Training Data:** This is used for training our neural network model.\n",
    "2. **Validation Data:** This is used for determining the configuration (i.e., hyperparameters) of our model in such a way that the model does not overfit to the training set.\n",
    "3. **Test Data:** This is used to estimate the performance of our trained model on unlabeled data.\n",
    "4. **Unlabeled Data:** The trained model is applied on this data to obtain predictions, which can then be used for downstream tasks in practical application scenarios.\n",
    "\n",
    "We download these four data sets to the `sample_data` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gvPSNrnUuHNF"
   },
   "outputs": [],
   "source": [
    "!mkdir -p sample_data\n",
    "!wget -qnc -P sample_data https://raw.githubusercontent.com/sidharthms/deepmatcher/master/examples/sample_data/amz_goog_train.csv\n",
    "!wget -qnc -P sample_data https://raw.githubusercontent.com/sidharthms/deepmatcher/master/examples/sample_data/amz_goog_validation.csv\n",
    "!wget -qnc -P sample_data https://raw.githubusercontent.com/sidharthms/deepmatcher/master/examples/sample_data/amz_goog_test.csv\n",
    "!wget -qnc -P sample_data https://raw.githubusercontent.com/sidharthms/deepmatcher/master/examples/sample_data/amz_goog_unlabeled.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how our data looks like, let's take a peek at the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>left_id</th>\n",
       "      <th>left_title</th>\n",
       "      <th>left_manufacturer</th>\n",
       "      <th>left_price</th>\n",
       "      <th>right_id</th>\n",
       "      <th>right_title</th>\n",
       "      <th>right_manufacturer</th>\n",
       "      <th>right_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571</td>\n",
       "      <td>microsoft visio standard 2007 version upgrade</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>129.95</td>\n",
       "      <td>946</td>\n",
       "      <td>adobe cs3 design standard upgrade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "      <td>microsoft mappoint 2006 with gps</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>349.00</td>\n",
       "      <td>2423</td>\n",
       "      <td>microsoft student with encarta premium 2008 co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>adobe after effects professional 7.0</td>\n",
       "      <td>adobe</td>\n",
       "      <td>999.00</td>\n",
       "      <td>2839</td>\n",
       "      <td>adobe flash cs3 professional ( mac )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>699.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1162</td>\n",
       "      <td>motu digital performer 5 digital audio softwar...</td>\n",
       "      <td>motu</td>\n",
       "      <td>395.00</td>\n",
       "      <td>2109</td>\n",
       "      <td>motu digital performer dp5 software music prod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>741</td>\n",
       "      <td>illustrator cs3 13 mac ed 1u</td>\n",
       "      <td>adobe-education-box</td>\n",
       "      <td>199.00</td>\n",
       "      <td>358</td>\n",
       "      <td>adobe illustrator cs3 for mac academic</td>\n",
       "      <td>adobe-education-box</td>\n",
       "      <td>199.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  left_id                                         left_title  \\\n",
       "0   0      0      571      microsoft visio standard 2007 version upgrade   \n",
       "1   1      0      574                   microsoft mappoint 2006 with gps   \n",
       "2   2      0      250               adobe after effects professional 7.0   \n",
       "3   3      1     1162  motu digital performer 5 digital audio softwar...   \n",
       "4   4      1      741                       illustrator cs3 13 mac ed 1u   \n",
       "\n",
       "     left_manufacturer  left_price  right_id  \\\n",
       "0            microsoft      129.95       946   \n",
       "1            microsoft      349.00      2423   \n",
       "2                adobe      999.00      2839   \n",
       "3                 motu      395.00      2109   \n",
       "4  adobe-education-box      199.00       358   \n",
       "\n",
       "                                         right_title   right_manufacturer  \\\n",
       "0                  adobe cs3 design standard upgrade                  NaN   \n",
       "1  microsoft student with encarta premium 2008 co...                  NaN   \n",
       "2               adobe flash cs3 professional ( mac )                  NaN   \n",
       "3  motu digital performer dp5 software music prod...                  NaN   \n",
       "4             adobe illustrator cs3 for mac academic  adobe-education-box   \n",
       "\n",
       "   right_price  \n",
       "0       413.99  \n",
       "1        43.60  \n",
       "2       699.00  \n",
       "3       319.95  \n",
       "4       199.99  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('sample_data/amz_goog_train.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3034,
     "status": "ok",
     "timestamp": 1523947284733,
     "user": {
      "displayName": "Sidharth Mudgal",
      "photoUrl": "//lh6.googleusercontent.com/-3orlcyRRzwg/AAAAAAAAAAI/AAAAAAAAIWE/SWMfxLxjDVQ/s50-c-k-no/photo.jpg",
      "userId": "102382893000738863249"
     },
     "user_tz": 300
    },
    "id": "aCXeRwfHVM9R",
    "outputId": "fc3e52a2-f1c9-40c9-a28d-0c020b3b02ac"
   },
   "source": [
    "## Step 1. Process data\n",
    "\n",
    "Before we can use our data for training, `deepmatcher` needs to first load and process it in order to prepare it for neural network training. Currently `deepmatcher` only supports processing CSV files. Each CSV file is assumed to have the following kinds of columns:\n",
    "\n",
    "* **\"Left\" attributes (required):** Our goal is to match tuple pairs. \"Left\" attributes are columns that correspond to the \"left\" tuple or the first tuple in the tuple pair. These column names are expected to be prefixed with \"left_\" by default.\n",
    "* **\"Right\" attributes (required):** \"Right\" attributes are columns that correspond to the \"right\" tuple or the second tuple in the tuple pair. These column names are expected to be prefixed with \"right_\" by default.\n",
    "* **Label column (required for train, validation, test):** Column containing the labels (match or non-match) for each tuple pair. Expected to be named \"label\" by default\n",
    "* **ID column (required):** Column containing a unique ID for each tuple pair. This is for evaluation convenience.  Expected to be named \"id\" by default.\n",
    "\n",
    "More details on what data processing involves and ways to customize it are described in **[this notebook](https://github.com/sidharthms/deepmatcher/tree/master/examples/data_process.ipynb)**. \n",
    "\n",
    "### Processing train / validation / test data\n",
    "In order to process our train, validation and test CSV files we call `dm.process` in the following code snippet which will load and process the CSV files and return three processed `MatchingDataset` objects respectively. These dataset objects will later be used for training and evaluation. The basic parameters to `dm.proecss` are as follows:\n",
    "\n",
    "* **path (required): ** The path where all data is stored. This includes train, validation and test. `deepmatcher` may create new files in this directory to store information about these data sets. This allows subsequent `dm.process` calls to be much faster.\n",
    "* **train (required): ** File name of training data in `path` directory.\n",
    "* **validation (required): ** File name of validation data in `path` directory.\n",
    "* **test (optional): ** File name of test data in `path` directory.\n",
    "* **ignore_columns (optional): ** Any columns in the CSV files that you may want to ignore for the purposes of training. These should be included here. \n",
    "\n",
    "Note that the train, validation and test CSVs must all share the same schema, i.e., they should have the same columns. Processing data involves several steps and can take several minutes to complete, especially if this is the first time you are running the `deepmatcher` package.\n",
    "\n",
    "NOTE: If you are running this in Colab, you may get a message saying 'Memory usage is close to the limit.' You can safely ignore it for now. We are working on reducing the memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WJ37wi1HC9EJ"
   },
   "outputs": [],
   "source": [
    "train, validation, test = dm.process(\n",
    "    path='sample_data',\n",
    "    train='amz_goog_train.csv',\n",
    "    validation='amz_goog_validation.csv',\n",
    "    test='amz_goog_test.csv',\n",
    "    ignore_columns=('left_id', 'right_id'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peeking at processed data\n",
    "Let's take a look at how the processed data looks like. To do this, we get the raw `pandas` table corresponding to the processed training dataset object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>left_title</th>\n",
       "      <th>left_manufacturer</th>\n",
       "      <th>left_price</th>\n",
       "      <th>right_title</th>\n",
       "      <th>right_manufacturer</th>\n",
       "      <th>right_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>microsoft visio standard 2007 version upgrade</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>129.95</td>\n",
       "      <td>adobe cs3 design standard upgrade</td>\n",
       "      <td></td>\n",
       "      <td>413.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>microsoft mappoint 2006 with gps</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>349.0</td>\n",
       "      <td>microsoft student with encarta premium 2008 co...</td>\n",
       "      <td></td>\n",
       "      <td>43.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>adobe after effects professional 7.0</td>\n",
       "      <td>adobe</td>\n",
       "      <td>999.0</td>\n",
       "      <td>adobe flash cs3 professional ( mac )</td>\n",
       "      <td></td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>motu digital performer 5 digital audio softwar...</td>\n",
       "      <td>motu</td>\n",
       "      <td>395.0</td>\n",
       "      <td>motu digital performer dp5 software music prod...</td>\n",
       "      <td></td>\n",
       "      <td>319.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>illustrator cs3 13 mac ed 1u</td>\n",
       "      <td>adobe-education-box</td>\n",
       "      <td>199.0</td>\n",
       "      <td>adobe illustrator cs3 for mac academic</td>\n",
       "      <td>adobe-education-box</td>\n",
       "      <td>199.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  label                                         left_title  \\\n",
       "0  0      0      microsoft visio standard 2007 version upgrade   \n",
       "1  1      0                   microsoft mappoint 2006 with gps   \n",
       "2  2      0               adobe after effects professional 7.0   \n",
       "3  3      1  motu digital performer 5 digital audio softwar...   \n",
       "4  4      1                       illustrator cs3 13 mac ed 1u   \n",
       "\n",
       "     left_manufacturer left_price  \\\n",
       "0            microsoft     129.95   \n",
       "1            microsoft      349.0   \n",
       "2                adobe      999.0   \n",
       "3                 motu      395.0   \n",
       "4  adobe-education-box      199.0   \n",
       "\n",
       "                                         right_title   right_manufacturer  \\\n",
       "0                  adobe cs3 design standard upgrade                        \n",
       "1  microsoft student with encarta premium 2008 co...                        \n",
       "2               adobe flash cs3 professional ( mac )                        \n",
       "3  motu digital performer dp5 software music prod...                        \n",
       "4             adobe illustrator cs3 for mac academic  adobe-education-box   \n",
       "\n",
       "  right_price  \n",
       "0      413.99  \n",
       "1        43.6  \n",
       "2       699.0  \n",
       "3      319.95  \n",
       "4      199.99  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_table = train.get_raw_table()\n",
    "train_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processed attribute values have been tokenized and lowercased so they may not look exactly the same as the input training data. These modifications help the neural network generalize better, i.e., perform better on data not trained on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing unlabeled data\n",
    "\n",
    "`dm.process` can also be used to process unlabeled data, as shown in the code snippet below, so that you can perform prediction over it. The basic parameters to use `dm.process` for this case are as follows:\n",
    "\n",
    "* **path (required): ** The path where unlabeled data is stored.\n",
    "* **unlabeled (required): ** File name of unlabeled data in `path` directory.\n",
    "* **ignore_columns (optional): ** Any columns in the CSV file that you may want to ignore for the purposes of training. These should be included here.\n",
    "\n",
    "Note that the unlabeled CSV file must have the same schema as the train, validation and test CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load time: 0.7748610926792026\n",
      "Vocab time: 13.302086600102484\n",
      "Metadata time: 0.00011100154370069504\n"
     ]
    }
   ],
   "source": [
    "unlabeled = dm.process(\n",
    "    path='sample_data',\n",
    "    unlabeled='amz_goog_unlabeled.csv',\n",
    "    ignore_columns=('left_id', 'right_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Define neural network model\n",
    "\n",
    "In this step you tell `deepmatcher` what kind of neural network you would like to use for entity matching. The easiest way to do this is to use one of the several kinds of neural network models that comes built-in with `deepmatcher`. To use a built-in network, construct a `dm.MatchingModel` as follows:\n",
    "\n",
    "`model = dm.MatchingModel(attr_summarizer='<TYPE>')`\n",
    "\n",
    "where `<TYPE>` is one of `sif`, `rnn`, `attention` or `hybrid`. If you are not familiar with what these mean, we strongly recommend taking a look at either **[slides from our talk on deepmatcher](http://bit.do/deepmatcher-talk)** for a high level overview, or **[our paper](http://pages.cs.wisc.edu/~anhai/papers1/deepmatcher-sigmod18.pdf)** for a more detailed explanation. Here we give briefly describe the intuition behind these four model types:\n",
    "* **sif:** This model considers the **words** present in each attribute value pair to determine a match or non-match. It does not take word order into account.\n",
    "* **rnn:** This model considers the **sequences of words** present in each attribute value pair to determine a match or non-match.\n",
    "* **attention:** This model considers the **alignment of words** present in each attribute value pair to determine a match or non-match. It does not take word order into account.\n",
    "* **hybrid:** This model considers the **alignment of sequences of words** present in each attribute value pair to determine a match or non-match.\n",
    "\n",
    "`deepmatcher` is highly customizable and allows you to tune almost every aspect of the neural network model for your application scenario. **[This tutorial](https://github.com/sidharthms/deepmatcher/tree/master/examples/customize_network.ipynb)** discusses the structure of `MatchingModel`s and how they can be customized.\n",
    "\n",
    "For this tutorial, let's create a `hybrid` model for entity matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dm.MatchingModel(attr_summarizer='hybrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Train model\n",
    "\n",
    "Next, we train the defined neural network model using the processed training and validation data. To do so, we call the `run_train` method which takes the following basic parameters:\n",
    "\n",
    "* **train:** The processed training dataset object (of type `MatchingDataset`).\n",
    "* **validation:** The processed validation dataset object (of type `MatchingDataset`).\n",
    "* **epochs:** Number of times to go over the entire `train` data for training the model.\n",
    "* **batch_size:** Number of labeled examples (tuple pairs) to use for each training step. This value may be increased if you have a lot of training data and would like to speed up training. The optimal value is dataset dependent.\n",
    "* **best_save_path:** Path to save the best model.\n",
    "* **pos_neg_ratio**: The ratio of the weight of positive examples (matches) to weight of negative examples (non-matches). This value should be increased if you have fewer matches than non-matches in your data. The optimal value is dataset dependent.\n",
    "\n",
    "Many other aspects of the training algorithm can be customized. For details on this, please refer the API documentation for **[run_train]()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 7133105\n",
      "===>  TRAIN Epoch 1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   29.2 | Load Time:    2.5 || F1:  16.84 | Prec:  46.15 | Rec:  10.30 || Ex/s: 216.89\n",
      "\n",
      "===>  EVAL Epoch 1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:    4.3 | Load Time:    0.8 || F1:  19.58 | Prec:  53.85 | Rec:  11.97 || Ex/s: 445.27\n",
      "\n",
      "* Best F1: 19.58041958041958\n",
      "Saving best model...\n",
      "===>  TRAIN Epoch 2 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   29.4 | Load Time:    2.5 || F1:  57.38 | Prec:  60.22 | Rec:  54.79 || Ex/s: 215.46\n",
      "\n",
      "===>  EVAL Epoch 2 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:    4.3 | Load Time:    0.8 || F1:  56.37 | Prec:  66.09 | Rec:  49.15 || Ex/s: 448.61\n",
      "\n",
      "* Best F1: 56.37254901960784\n",
      "Saving best model...\n",
      "===>  TRAIN Epoch 3 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   29.4 | Load Time:    2.5 || F1:  73.42 | Prec:  70.43 | Rec:  76.68 || Ex/s: 215.51\n",
      "\n",
      "===>  EVAL Epoch 3 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:    4.3 | Load Time:    0.8 || F1:  63.49 | Prec:  61.69 | Rec:  65.38 || Ex/s: 447.22\n",
      "\n",
      "* Best F1: 63.485477178423245\n",
      "Saving best model...\n",
      "===>  TRAIN Epoch 4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   29.4 | Load Time:    2.5 || F1:  82.04 | Prec:  77.41 | Rec:  87.27 || Ex/s: 215.42\n",
      "\n",
      "===>  EVAL Epoch 4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    4.3 | Load Time:    0.8 || F1:  66.39 | Prec:  64.14 | Rec:  68.80 || Ex/s: 445.90\n",
      "\n",
      "* Best F1: 66.39175257731958\n",
      "Saving best model...\n",
      "===>  TRAIN Epoch 5 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   29.3 | Load Time:    2.5 || F1:  88.40 | Prec:  84.96 | Rec:  92.13 || Ex/s: 215.74\n",
      "\n",
      "===>  EVAL Epoch 5 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:    4.3 | Load Time:    0.8 || F1:  59.46 | Prec:  69.94 | Rec:  51.71 || Ex/s: 446.94\n",
      "\n",
      "===>  TRAIN Epoch 6 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   29.8 | Load Time:    2.6 || F1:  91.07 | Prec:  88.20 | Rec:  94.13 || Ex/s: 212.36\n",
      "\n",
      "===>  EVAL Epoch 6 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:    4.3 | Load Time:    0.8 || F1:  58.39 | Prec:  67.80 | Rec:  51.28 || Ex/s: 444.14\n",
      "\n",
      "===>  TRAIN Epoch 7 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   29.5 | Load Time:    2.5 || F1:  93.18 | Prec:  90.66 | Rec:  95.85 || Ex/s: 214.86\n",
      "\n",
      "===>  EVAL Epoch 7 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:    4.3 | Load Time:    0.8 || F1:  57.56 | Prec:  67.05 | Rec:  50.43 || Ex/s: 446.43\n",
      "\n",
      "===>  TRAIN Epoch 8 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   29.4 | Load Time:    2.6 || F1:  94.12 | Prec:  92.18 | Rec:  96.14 || Ex/s: 214.95\n",
      "\n",
      "===>  EVAL Epoch 8 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:    4.3 | Load Time:    0.8 || F1:  61.39 | Prec:  69.95 | Rec:  54.70 || Ex/s: 444.47\n",
      "\n",
      "===>  TRAIN Epoch 9 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   29.4 | Load Time:    2.5 || F1:  95.51 | Prec:  93.79 | Rec:  97.28 || Ex/s: 215.17\n",
      "\n",
      "===>  EVAL Epoch 9 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:    4.3 | Load Time:    0.8 || F1:  61.76 | Prec:  69.52 | Rec:  55.56 || Ex/s: 447.40\n",
      "\n",
      "===>  TRAIN Epoch 10 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   29.4 | Load Time:    2.5 || F1:  96.42 | Prec:  94.63 | Rec:  98.28 || Ex/s: 215.56\n",
      "\n",
      "===>  EVAL Epoch 10 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:    4.3 | Load Time:    0.8 || F1:  62.23 | Prec:  70.05 | Rec:  55.98 || Ex/s: 444.00\n",
      "\n",
      "===>  TRAIN Epoch 11 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 11 || Run Time:   29.5 | Load Time:    2.5 || F1:  97.17 | Prec:  96.08 | Rec:  98.28 || Ex/s: 214.71\n",
      "\n",
      "===>  EVAL Epoch 11 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 11 || Run Time:    4.3 | Load Time:    0.8 || F1:  62.59 | Prec:  69.63 | Rec:  56.84 || Ex/s: 445.26\n",
      "\n",
      "===>  TRAIN Epoch 12 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 12 || Run Time:   29.4 | Load Time:    2.5 || F1:  97.94 | Prec:  97.05 | Rec:  98.86 || Ex/s: 214.97\n",
      "\n",
      "===>  EVAL Epoch 12 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 12 || Run Time:    4.4 | Load Time:    0.8 || F1:  62.94 | Prec:  69.23 | Rec:  57.69 || Ex/s: 441.22\n",
      "\n",
      "===>  TRAIN Epoch 13 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 13 || Run Time:   29.6 | Load Time:    2.6 || F1:  98.22 | Prec:  97.60 | Rec:  98.86 || Ex/s: 213.47\n",
      "\n",
      "===>  EVAL Epoch 13 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 13 || Run Time:    4.3 | Load Time:    0.8 || F1:  63.49 | Prec:  67.63 | Rec:  59.83 || Ex/s: 447.88\n",
      "\n",
      "===>  TRAIN Epoch 14 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 14 || Run Time:   29.6 | Load Time:    2.6 || F1:  98.58 | Prec:  97.88 | Rec:  99.28 || Ex/s: 213.55\n",
      "\n",
      "===>  EVAL Epoch 14 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 14 || Run Time:    4.4 | Load Time:    0.9 || F1:  63.84 | Prec:  66.82 | Rec:  61.11 || Ex/s: 437.36\n",
      "\n",
      "===>  TRAIN Epoch 15 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 15 || Run Time:   30.6 | Load Time:    2.6 || F1:  99.07 | Prec:  98.72 | Rec:  99.43 || Ex/s: 207.46\n",
      "\n",
      "===>  EVAL Epoch 15 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 15 || Run Time:    4.4 | Load Time:    0.8 || F1:  62.75 | Prec:  66.51 | Rec:  59.40 || Ex/s: 440.20\n",
      "\n",
      "Loading best model...\n"
     ]
    }
   ],
   "source": [
    "model.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=15,\n",
    "    batch_size=16,\n",
    "    best_save_path='hybrid_model.pth',\n",
    "    pos_weight=1.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Apply model to new data\n",
    "\n",
    "#### Evaluating on test data\n",
    "Now that we have a trained model for entity matching, we can now evaluate its accuracy on test data, to estimate the performance of the model on unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  EVAL Epoch 4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    2.2 | Load Time:    0.8 || F1:  69.86 | Prec:  65.54 | Rec:  74.79 || Ex/s: 760.45\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.86027944111775"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute F1 on test set\n",
    "model.run_eval(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting predictions on unlabeled data\n",
    "\n",
    "We finally apply the trained model to unlabeled data to get predictions. To do this, we call the `run_prediction` method which takes a processed data set object and returns a `pandas` dataframe containing tuple pair IDs (`id` column) and the corresponding match / non-match predictions (`prediction` column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    2.3 | Load Time:    0.8 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>0.874860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.044076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0.083617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>0.664423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>0.068327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      match_score\n",
       "id               \n",
       "2174     0.874860\n",
       "1757     0.044076\n",
       "1235     0.083617\n",
       "1112     0.664423\n",
       "1091     0.068327"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.run_prediction(unlabeled)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may optionally set the `output_attributes` parameter to also include all attributes present in the original input table. As mentioned earlier, the processed attribute values will likely look a bit different from the attribute values in the input CSV files due to modifications such as tokenization and lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    2.2 | Load Time:    0.8 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_score</th>\n",
       "      <th>left_id</th>\n",
       "      <th>left_title</th>\n",
       "      <th>left_manufacturer</th>\n",
       "      <th>left_price</th>\n",
       "      <th>right_id</th>\n",
       "      <th>right_title</th>\n",
       "      <th>right_manufacturer</th>\n",
       "      <th>right_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>0.874860</td>\n",
       "      <td>314</td>\n",
       "      <td>zipmagic personal edition</td>\n",
       "      <td>allume systems</td>\n",
       "      <td>19.95</td>\n",
       "      <td>3070</td>\n",
       "      <td>zipmagic personal edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0.044076</td>\n",
       "      <td>1164</td>\n",
       "      <td>g7 kontakt edition</td>\n",
       "      <td>sibelius-software-ltd .</td>\n",
       "      <td>99.99</td>\n",
       "      <td>1103</td>\n",
       "      <td>chatchecker family edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0.083617</td>\n",
       "      <td>1310</td>\n",
       "      <td>ca antivirus 2007</td>\n",
       "      <td>computer associates</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2801</td>\n",
       "      <td>ca anti-spyware 2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>0.664423</td>\n",
       "      <td>300</td>\n",
       "      <td>police quest compilation</td>\n",
       "      <td>vivendi games</td>\n",
       "      <td>19.99</td>\n",
       "      <td>2985</td>\n",
       "      <td>police quest compilation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>1323</td>\n",
       "      <td>simple slide show</td>\n",
       "      <td>topics entertainment</td>\n",
       "      <td>19.99</td>\n",
       "      <td>2157</td>\n",
       "      <td>simple movie maker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      match_score  left_id                 left_title  \\\n",
       "id                                                      \n",
       "2174     0.874860      314  zipmagic personal edition   \n",
       "1757     0.044076     1164         g7 kontakt edition   \n",
       "1235     0.083617     1310          ca antivirus 2007   \n",
       "1112     0.664423      300   police quest compilation   \n",
       "1091     0.068327     1323          simple slide show   \n",
       "\n",
       "            left_manufacturer  left_price  right_id  \\\n",
       "id                                                    \n",
       "2174           allume systems       19.95      3070   \n",
       "1757  sibelius-software-ltd .       99.99      1103   \n",
       "1235      computer associates       39.95      2801   \n",
       "1112            vivendi games       19.99      2985   \n",
       "1091     topics entertainment       19.99      2157   \n",
       "\n",
       "                     right_title right_manufacturer  right_price  \n",
       "id                                                                \n",
       "2174   zipmagic personal edition                NaN         8.95  \n",
       "1757  chatchecker family edition                NaN        29.99  \n",
       "1235        ca anti-spyware 2007                NaN        24.99  \n",
       "1112    police quest compilation                NaN        18.95  \n",
       "1091          simple movie maker                NaN        12.90  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.run_prediction(unlabeled, output_attributes=True)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then save these predictions to CSV and use them for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('sample_data/unlabeled_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting predictions on labeled data\n",
    "\n",
    "You can also get predictions for labeled data such as validation data. To do so, you can simply call the `run_prediction` method passing the validation data as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    7.7 | Load Time:    3.3 || F1:  85.51 | Prec:  77.75 | Rec:  94.99 || Ex/s: 626.73\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_score</th>\n",
       "      <th>label</th>\n",
       "      <th>left_id</th>\n",
       "      <th>left_title</th>\n",
       "      <th>left_manufacturer</th>\n",
       "      <th>left_price</th>\n",
       "      <th>right_id</th>\n",
       "      <th>right_title</th>\n",
       "      <th>right_manufacturer</th>\n",
       "      <th>right_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>0.073800</td>\n",
       "      <td>0</td>\n",
       "      <td>883</td>\n",
       "      <td>adobe creative suite cs3 production premium</td>\n",
       "      <td>adobe</td>\n",
       "      <td>1699.00</td>\n",
       "      <td>369</td>\n",
       "      <td>adobe cs3 design premium upsell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1639.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>0.036878</td>\n",
       "      <td>0</td>\n",
       "      <td>1078</td>\n",
       "      <td>3d home architect home v. 8 by encore software</td>\n",
       "      <td>encore software</td>\n",
       "      <td>39.99</td>\n",
       "      <td>2589</td>\n",
       "      <td>encore software 10444 elementary school advant...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.030550</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>instant immersion japanese ( audio book )</td>\n",
       "      <td>topics entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2313</td>\n",
       "      <td>instant immersion italian platinum ( win 95 98...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>0.040486</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>microsoft windows server 2003 client additiona...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>209.00</td>\n",
       "      <td>2853</td>\n",
       "      <td>microsoft windows xp professional edition ( up...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>0.977979</td>\n",
       "      <td>1</td>\n",
       "      <td>721</td>\n",
       "      <td>backpack journalist</td>\n",
       "      <td>honest technology</td>\n",
       "      <td>79.99</td>\n",
       "      <td>447</td>\n",
       "      <td>global marketing partners backpack journalist ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      match_score  label  left_id  \\\n",
       "id                                  \n",
       "1690     0.073800      0      883   \n",
       "6749     0.036878      0     1078   \n",
       "4606     0.030550      0      176   \n",
       "3661     0.040486      0      431   \n",
       "5323     0.977979      1      721   \n",
       "\n",
       "                                             left_title     left_manufacturer  \\\n",
       "id                                                                              \n",
       "1690        adobe creative suite cs3 production premium                 adobe   \n",
       "6749     3d home architect home v. 8 by encore software       encore software   \n",
       "4606          instant immersion japanese ( audio book )  topics entertainment   \n",
       "3661  microsoft windows server 2003 client additiona...             microsoft   \n",
       "5323                                backpack journalist     honest technology   \n",
       "\n",
       "      left_price  right_id                                        right_title  \\\n",
       "id                                                                              \n",
       "1690     1699.00       369                    adobe cs3 design premium upsell   \n",
       "6749       39.99      2589  encore software 10444 elementary school advant...   \n",
       "4606         NaN      2313  instant immersion italian platinum ( win 95 98...   \n",
       "3661      209.00      2853  microsoft windows xp professional edition ( up...   \n",
       "5323       79.99       447  global marketing partners backpack journalist ...   \n",
       "\n",
       "     right_manufacturer  right_price  \n",
       "id                                    \n",
       "1690                NaN      1639.99  \n",
       "6749                NaN        25.97  \n",
       "4606                NaN       129.99  \n",
       "3661                NaN       199.99  \n",
       "5323                NaN        83.27  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions = model.run_prediction(train, output_attributes=True)\n",
    "valid_predictions.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "getting_started.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
